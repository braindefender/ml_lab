# Лабораторные работы

## 1. Линейные методы классификации.

### Задачи:

1. Загрузка и обзор данных.

- Загрузить таблицу `Iris` из репозитория UCI (можно из любого доступного источника: UCI, sklearn, kaggle).
- Поместить данные в объект `DataFrame` библиотеки pandas.
- Вычислить корреляции между признаками на всей таблице и отдельно по классам (использовать `pd.groupby`).
- Визуализировать распределения классов на всех парах переменных.

2. Применение алгоритмов

- Выбрать две переменные.
- Построить и визуализировать (показать разделяющую кривую, пример подходящей визуализации есть в документации sklearn) решения методами:
  - линейный дискриминант,
  - квадратичный дискриминант,
  - логистическая регрессия,
  - SVM (линейное и квадратичное ядро).

> В следующих заданиях можно оставить только два (наименее разделимых) класса.

3. Построить линейный дискриминант на всех переменных. Визуализировать ответы алгоритма (выделить, например, цветом) и классы объектов (выделить, например, формой маркеров) во всех двумерных подпространствах.

4. На двух переменных из п2 вычислить квадратичную разделяющую функцию непосредственно по оценкам ковариационных матриц и средних (самостоятельно реализовать метод, не используя готовый). Визуализировать её и сравнить с решением из п2.

## 2. «Наивный» байесовский классификатор.

### Задачи:

1. Загрузить таблицу `Mushroom` из репозитория UCI (либо любого другого источника) в объект `DataFrame`. Вычислить распределение значений категориальных признаков по классам (использовать `pd.groupby`).
   Визуализировать распределения.

2. Построить решающую функцию по каждой переменной на основе частот. Найти наиболее информативную переменную.

3. Построить «наивный» байесовский классификатор из sklearn. Оценить точность.

4. Самостоятельно реализовать метод, не используя готовый. Сравнить полученное решение с библиотечным. Добавить регуляризатор в оценки частот.
